{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3bPMp9EhJ8oSlYy2zGA1G"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOjbQ6DP7eyT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BioGptTokenizer, BioGptForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, accuracy_score, classification_report\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"D:/Downloads/newData.csv\")\n",
        "\n",
        "# Use this code if you want to preprocess the dataset\n",
        "'''\n",
        "# load english language model and create nlp object from it\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess(text):\n",
        "    doc = nlp(text)\n",
        "    filtered_tokens = []\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct:\n",
        "            continue\n",
        "        filtered_tokens.append(token.lemma_)\n",
        "    return \" \".join(filtered_tokens)\n",
        "\n",
        "df['preprocessed_txt'] = df['Report'].apply(preprocess)\n",
        "'''\n",
        "# Preprocessing the text data\n",
        "#df['preprocessed_txt'] = df['Report']  # Use the original text without extra preprocessing\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['Report'],\n",
        "    df['BIRADS'],\n",
        "    test_size=0.2,\n",
        "    random_state=2022,\n",
        "    stratify=df['BIRADS']\n",
        ")\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 30\n",
        "MAX_LEN = 128\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "# Tokenizer for BioGPT\n",
        "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
        "\n",
        "# Prepare custom Dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx] - 1  # Convert labels from 1-5 to 0-4 for BioGPT compatibility\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Convert datasets to torch Datasets\n",
        "train_dataset = TextDataset(X_train.tolist(), y_train.tolist(), tokenizer, MAX_LEN)\n",
        "test_dataset = TextDataset(X_test.tolist(), y_test.tolist(), tokenizer, MAX_LEN)\n",
        "\n",
        "# Data loaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Define the BioGPT-based model\n",
        "class BioGPTClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_classes):\n",
        "        super(BioGPTClassifier, self).__init__()\n",
        "        self.biogpt = BioGptForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        return self.biogpt(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "\n",
        "# Instantiate the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BioGPTClassifier(model_name=\"microsoft/biogpt\", num_classes=NUM_CLASSES)\n",
        "model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "class_weights = torch.tensor([1.0, 0.5, 1.5, 2.0, 3.0], dtype=torch.float).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss/len(train_dataloader)}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Adjust predicted and true labels back to original range (1 to 5)\n",
        "predictions = [p+1 for p in predictions]\n",
        "true_labels = [t+1 for t in true_labels]\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(true_labels, predictions, target_names=[str(i+1) for i in range(NUM_CLASSES)]))\n",
        "\n",
        "# Calculate Accuracy and Macro Average Recall with 95% Confidence Interval\n",
        "def compute_confidence_interval(metric_func, true_labels, predictions, confidence=0.95):\n",
        "    # Compute the metric (accuracy or recall)\n",
        "    metric = metric_func(true_labels, predictions)\n",
        "\n",
        "    # Calculate standard error\n",
        "    se_metric = np.sqrt(metric * (1 - metric) / len(true_labels)) if len(true_labels) > 1 else np.nan\n",
        "    ci_lower, ci_upper = stats.norm.interval(confidence, loc=metric, scale=se_metric) if len(true_labels) > 1 else (np.nan, np.nan)\n",
        "\n",
        "    return metric, ci_lower, ci_upper\n",
        "\n",
        "# Accuracy\n",
        "accuracy, ci_acc_lower, ci_acc_upper = compute_confidence_interval(accuracy_score, true_labels, predictions)\n",
        "\n",
        "# Macro average recall\n",
        "macro_recall = recall_score(true_labels, predictions, average='macro')\n",
        "\n",
        "# For macro recall confidence interval\n",
        "if len(true_labels) > 1:\n",
        "    recalls = recall_score(true_labels, predictions, average=None)\n",
        "    se_recall = np.std(recalls, ddof=1) / np.sqrt(len(recalls))  # Standard error\n",
        "    recall_ci_lower, recall_ci_upper = stats.norm.interval(0.95, loc=macro_recall, scale=se_recall)\n",
        "else:\n",
        "    recall_ci_lower, recall_ci_upper = (np.nan, np.nan)\n",
        "\n",
        "# Output results\n",
        "print(f\"Accuracy: {accuracy:.4f}, 95% CI: ({ci_acc_lower:.4f}, {ci_acc_upper:.4f})\")\n",
        "print(f\"Macro Average Recall: {macro_recall:.4f}, 95% CI: ({recall_ci_lower:.4f}, {recall_ci_upper:.4f})\")\n"
      ]
    }
  ]
}